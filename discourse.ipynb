{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import praw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=\"gMMUyYPztGnIEw\",\n",
    "                     client_secret=\"BxzKaCmGcvlkxW7TmNnN4NIa6GI\",\n",
    "                     user_agent=\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36\")\n",
    "num_app= 0\n",
    "num_hum= 1\n",
    "num_disag= 2\n",
    "num_ann= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(disType):\n",
    "    if(disType== \"elaboration\"):\n",
    "        return 0\n",
    "    elif(disType== \"agreement\"):\n",
    "        return 1\n",
    "    elif(disType== \"disagreement\"):\n",
    "        return 2\n",
    "    elif(disType== \"appreciation\"):\n",
    "        return 3\n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_json():\n",
    "    loc= '/home/bansal/Downloads/discourse_reddit_betterviralitycomments.json'\n",
    "    scores= []\n",
    "    subreddits= set()\n",
    "    counts= np.zeros(4)\n",
    "    for comment in open(loc, 'r'):\n",
    "        post= json.loads(comment)#nice\n",
    "        subreddits.add(post['subreddit'])\n",
    "        \n",
    "    return subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json():\n",
    "    counts= np.zeros(4)#appreciation, humor, question, announcement\n",
    "    df= pd.read_csv('/home/bansal/Downloads/subreddits_basic.csv')\n",
    "    with open('/home/bansal/Downloads/coarse_discourse_dataset.json') as jsonfile:\n",
    "        lines = jsonfile.readlines()\n",
    "        discoursedata = open('/home/bansal/Downloads/discourse_reddit_betterviralitycomments3.json', 'w')\n",
    "        for line in lines:\n",
    "            reader = json.loads(line)\n",
    "            print(reader['url'])\n",
    "            subreddit= reader['subreddit']\n",
    "            subs= int(df.loc[df['reddit']== subreddit, 'subs'].values)\n",
    "            submission = reddit.submission(url=reader['url'])\n",
    "            submission.comment_sort = 'best'\n",
    "            submission.comment_limit = 40\n",
    "            post_dict= {}\n",
    "            try:\n",
    "                for post in reader['posts']:\n",
    "#                     print (\"GOTCHA:\" + post['majority_type'])\n",
    "                    if(\"majority_type\" in post):\n",
    "                        a= find(post['majority_type'])\n",
    "                        if(a!= -1):\n",
    "                            counts[a]+= 1\n",
    "                            post_dict[post['id']]= post\n",
    "\n",
    "\n",
    "                full_submission_id = 't3_' + submission.id\n",
    "                if full_submission_id in post_dict:\n",
    "#                     post_dict[full_submission_id]['body'] = submission.selftext\n",
    "                    # For a self-post, this URL will be the same URL as the thread.\n",
    "                    # For a link-post, this URL will be the link that the link-post is linking to.\n",
    "                    post_dict[full_submission_id]['url'] = submission.url\n",
    "#                     post_dict[full_submission_id]['virality']= abs(submission.ups) + abs(submission.downs) + len(reader['posts']) - 1\n",
    "                    if submission.author:\n",
    "                        post_dict[full_submission_id]['author'] = submission.author.name\n",
    "\n",
    "\n",
    "                submission.comments.replace_more(limit=0)\n",
    "                for comment in submission.comments.list():\n",
    "                    full_comment_id = 't1_' + comment.id\n",
    "                    if full_comment_id in post_dict:\n",
    "                        post_dict[full_comment_id]['id']= full_comment_id\n",
    "                        post_dict[full_comment_id]['body'] = comment.body\n",
    "                        count= 0\n",
    "                        for post in reader['posts']:\n",
    "                            if('in_reply_to' in post and post['in_reply_to']== full_comment_id):\n",
    "                                count+= 1\n",
    "                        if(len(subs)> 0 and subs[0]!= 0):\n",
    "                            post_dict[full_comment_id]['virality']= (abs(comment.ups) + abs(comment.downs) + count)/(subs[0])\n",
    "                        if comment.author:\n",
    "                            post_dict[full_comment_id]['author'] = comment.author.name\n",
    "                            \n",
    "            except Exception as e:\n",
    "                print('Error %s' % (e))\n",
    "\n",
    "            found_count = 0\n",
    "            for post in reader['posts']:\n",
    "                if not 'body' in post.keys():\n",
    "                    print(\"Can't find %s in URL: %s\" % (post['id'], reader['url']))\n",
    "                else:\n",
    "                    found_count += 1\n",
    "\n",
    "            print('Found %s posts out of %s' % (found_count, len(reader['posts'])))\n",
    "\n",
    "            discoursedata.write(json.dumps(reader) + '\\n')\n",
    "            time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json2(filename):\n",
    "    fullname= '/home/bansal/Downloads/' + filename + '.json'\n",
    "    print (fullname)\n",
    "    with open(fullname, 'r') as data_file:\n",
    "        data= json.load(data_file)\n",
    "        opfile= open('/home/bansal/Downloads/' + filename + 'op.json', 'w')\n",
    "        count= 0\n",
    "        for post in data:\n",
    "            if(post['link_id']== post['parent_id']):\n",
    "                post_dict= {}\n",
    "                submission= reddit.submission(id= post['link_id'][3:])\n",
    "                try:\n",
    "                    post_dict['body']= submission.selftext\n",
    "                    post_dict['url']= submission.url\n",
    "                    print (submission.url)\n",
    "                    post_dict['virality']= abs(submission.ups) + abs(submission.downs) + len(submission.comments)\n",
    "                    post_dict['author']= submission.author.name\n",
    "                    opfile.write(json.dumps(post_dict) + '\\n')\n",
    "                    count+= 1\n",
    "                    print (count)\n",
    "                    time.sleep(2)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "        print (\"The final count is: \" + count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
